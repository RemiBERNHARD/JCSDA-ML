{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs: \n",
      "    - pygrib\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libnetcdf-4.6.1            |       h5e45101_3         1.3 MB  conda-forge\n",
      "    openssl-1.0.2p             |       h470a237_1         3.1 MB  conda-forge\n",
      "    pygrib-2.0.3               |   py36h5688137_0         1.2 MB  conda-forge\n",
      "    hdf4-4.2.13                |                0         969 KB  conda-forge\n",
      "    eccodes-2.8.2              |       ha8b302a_0         5.6 MB  conda-forge\n",
      "    proj4-4.9.3                |       h470a237_8         3.2 MB  conda-forge\n",
      "    pyproj-1.9.5.1             |   py36h508ed2a_5         134 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        15.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    eccodes:   2.8.2-ha8b302a_0       conda-forge\n",
      "    hdf4:      4.2.13-0               conda-forge\n",
      "    jasper:    1.900.1-4              conda-forge\n",
      "    libnetcdf: 4.6.1-h5e45101_3       conda-forge\n",
      "    proj4:     4.9.3-h470a237_8       conda-forge\n",
      "    pygrib:    2.0.3-py36h5688137_0   conda-forge\n",
      "    pyproj:    1.9.5.1-py36h508ed2a_5 conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    certifi:   2018.8.24-py36_1       conda-forge --> 2018.8.24-py36_1001 conda-forge\n",
      "    openssl:   1.0.2p-h470a237_0      conda-forge --> 1.0.2p-h470a237_1   conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libnetcdf-4.6.1      | 1.3 MB    | ##################################### | 100% \n",
      "openssl-1.0.2p       | 3.1 MB    | ##################################### | 100% \n",
      "pygrib-2.0.3         | 1.2 MB    | ##################################### | 100% \n",
      "hdf4-4.2.13          | 969 KB    | ##################################### | 100% \n",
      "eccodes-2.8.2        | 5.6 MB    | ##################################### | 100% \n",
      "proj4-4.9.3          | 3.2 MB    | ##################################### | 100% \n",
      "pyproj-1.9.5.1       | 134 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "import subprocess\n",
    "import re \n",
    "from io import StringIO \n",
    "from datetime import date, timedelta, datetime \n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!conda install -c conda-forge pygrib -n python3 -y\n",
    "import pygrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = np.arange(24)\n",
    "fxx = [0]\n",
    "field = 'prs'\n",
    "model = 'hrrr'\n",
    "sDATE = date(2017, 1, 1)          # Start date\n",
    "eDATE = date(2017, 12, 31)          # End date (exclusive)\n",
    "days = (eDATE-sDATE).days\n",
    "DATES = [sDATE + timedelta(days=d) for d in range(days)]\n",
    "\n",
    "d = DATES[0]\n",
    "\n",
    "# for h in np.arange(10):\n",
    "#     path_grb2 = \"%s_%s.t%02dz.wrf%sf%02d.grib2\" % (d.strftime('%Y%m%d'), model, h, field, fxx[0])\n",
    "#     bucket_name = 'jedi-pub'\n",
    "#     key_data = 'remi/' + path_grb2\n",
    "#     s3 = boto3.resource('s3')\n",
    "#     s3.Bucket(bucket_name).download_file(key_data, path_grb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which return a matrix with all date from an hour\n",
    "def one_hour_mat(d, model, hour, field, forecast):\n",
    "    var_name = ['']*686\n",
    "    mat_res = np.zeros((1905141,686))\n",
    "    path_grb2 = \"%s_%s.t%02dz.wrf%sf%02d.grib2\" % (d.strftime('%Y%m%d'), model, hour, field, forecast)\n",
    "    grbs = pygrib.open(path_grb2)\n",
    "    for j in range(684):\n",
    "        grb = grbs.readline()\n",
    "        var_name[j] = grb.name\n",
    "        mat_res[:,j] =  grb.values.flatten()\n",
    "    lats, lons = grb.latlons()    \n",
    "    mat_res[:,684] = lats.flatten()\n",
    "    mat_res[:,685] = lons.flatten()\n",
    "    grbs.close()\n",
    "    mat_res[np.where(mat_res==9.969209968386869e+36)] = 0\n",
    "    return (mat_res, np.array(var_name))\n",
    "\n",
    "#Function to scale matrices\n",
    "def scale_matrices(X_train, y_train, X_test, y_test, X_valid=None, y_valid=None):\n",
    "    y_train = np.reshape(y_train, (-1,1))\n",
    "    y_test = np.reshape(y_test, (-1,1))\n",
    "    if (y_valid is not None):\n",
    "        y_valid = np.reshape(y_valid, (-1,1))\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    if (X_valid is not None):\n",
    "        X_valid = scaler.transform(X_valid)\n",
    "    scaler.fit(y_train)\n",
    "    y_train = scaler.transform(y_train)\n",
    "    y_test = scaler.transform(y_test)\n",
    "    if (y_valid is not None):\n",
    "        y_valid = scaler.transform(y_valid)\n",
    "    if (y_valid is not None):      \n",
    "        return(X_train, X_test, y_train, y_test, X_valid, y_valid, scaler)    \n",
    "    else:\n",
    "        return(X_train, X_test, y_train, y_test, scaler)\n",
    "\n",
    "#Function to print the n most important variables in a linear regresssion\n",
    "def linreg_mostvar(reglin_coeffs,var_name, n):\n",
    "    var = ['']*n\n",
    "    for i in range(n):\n",
    "        var[i] =  var_name[np.where(reglin_coeffs==np.sort(reglin_coeffs)[0,i] )[1][0]  ]\n",
    "    return(var)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1905141, 686)\n"
     ]
    }
   ],
   "source": [
    "#Get the full data matrix\n",
    "#start = time.time()\n",
    "# start = time.time()\n",
    "mat_tot, var_name = one_hour_mat(d, model, 0, field, fxx[0])\n",
    "# print(mat_tot.shape)\n",
    "# for h in np.arange(1,3):\n",
    "#     mat_tot = np.append(mat_tot, one_hour_mat(d, model, h, field, fxx[0])[0], axis=0)    \n",
    "# end = time.time()\n",
    "# print(end-start)\n",
    "print(mat_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1524112, 682)\n",
      "(1524112, 1)\n",
      "(381029, 682)\n",
      "(381029, 1)\n"
     ]
    }
   ],
   "source": [
    "#Prepare matrices\n",
    "Y = mat_tot[:,np.shape(mat_tot)[1]-6]\n",
    "indices = np.array([i for i in range(np.shape(mat_tot)[1]-6)])\n",
    "indices = np.append(indices,[np.shape(mat_tot)[1]-2,np.shape(mat_tot)[1]-1])\n",
    "X = mat_tot[:,indices]\n",
    "del(mat_tot)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler = scale_matrices(X_train, y_train, X_test, y_test)\n",
    "\n",
    "del(X)\n",
    "del(Y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.92035937309265\n"
     ]
    }
   ],
   "source": [
    "#Perform a linear regression\n",
    "start = time.time()\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980995623583358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01883458354013145"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reg.score(X_train,y_train))\n",
    "y_predict = reg.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_predict))\n",
    "print(mean_squared_error(scaler.inverse_transform(y_test), scaler.inverse_transform(y_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
