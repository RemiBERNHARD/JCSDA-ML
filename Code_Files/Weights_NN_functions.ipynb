{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, activation='linear'))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "X_train = np.random.normal(0,1,(10000,4))\n",
    "\n",
    "a = np.reshape(2*X_train[:,0] + 1.5*X_train[:,1] + 0.6*X_train[:,2] + 1.2*X_train[:,3], (10000,1))\n",
    "b = np.reshape(1*X_train[:,0] + 0.5*X_train[:,1] + 1.6*X_train[:,2] + 2.2*X_train[:,3], (10000,1))\n",
    "y_train = np.concatenate((a,b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "#Print weights without biais weigths after each epoch\n",
    "print_weights_aftereachepoch = LambdaCallback(on_epoch_end=lambda epoch, logs: print(model.layers[0].get_weights()))\n",
    "model.fit(X_train, y_train,  verbose=1, epochs=5, batch_size=1000, callbacks = [print_weights_aftereachepoch])\n",
    "\n",
    "#Print weights without biais weigths after each batch\n",
    "print_weights_aftereachbatch = LambdaCallback(on_batch_end=lambda batch, logs: print(model.layers[0].get_weights()))\n",
    "model.fit(X_train, y_train,  verbose=1, epochs=5, batch_size=1000, callbacks = [print_weights_aftereachbatch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "#Save model weigths each N epochs (use load.weights for another model after)\n",
    "class WeightsSaver(Callback):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if self.epoch % self.N == 0:\n",
    "            name = 'weights%08d.h5' % self.epoch\n",
    "            self.model.save_weights(name)\n",
    "        self.epoch += 1\n",
    "        \n",
    "model.fit(X_train, y_train, epochs=5, batch_size=1000, callbacks=[WeightsSaver(1)])\n",
    "\n",
    "\n",
    "#Save model weigths each N batches (use load.weights for another model after)\n",
    "class WeightsSaver(Callback):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        self.batch = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if self.batch % self.N == 0:\n",
    "            name = 'weights%08d.h5' % self.batch\n",
    "            self.model.save_weights(name)\n",
    "        self.batch += 1\n",
    "        \n",
    "model.fit(X_train, y_train, epochs=5, batch_size=1000, callbacks=[WeightsSaver(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "#Function to have weights saved in a variable each N epochs\n",
    "class WeightsSaver(Callback):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        self.epoch = 0\n",
    "        self.epoch_weights= {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if self.epoch % self.N == 0:\n",
    "            self.epoch_weights[self.epoch] = self.model.get_weights()\n",
    "        self.epoch += 1\n",
    "\n",
    "checkpoint = WeightsSaver(1)\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=1000, callbacks=[checkpoint])\n",
    "#example : checkpoint.epoch_weights[0] contains the weights at the end of the first epoch\n",
    "\n",
    "#Function to have weights saved in a variable each N epochs\n",
    "class WeightsSaver(Callback):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        self.batch = 0\n",
    "        self.batch_weights= {}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if self.batch % self.N == 0:\n",
    "            self.batch_weights[self.batch] = self.model.get_weights()\n",
    "        self.batch += 1\n",
    "\n",
    "checkpoint = WeightsSaver(1)\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=1000, callbacks=[checkpoint])\n",
    "#example : checkpoint.batch_weights][11] contains the weihts at the end of the 12th batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
